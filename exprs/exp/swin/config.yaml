model:                    # architecture details
    type: resnext50_32x4d        # model name
    kwargs:
        num_classes: 1000 # number of classes
        bn:
            use_sync_bn: False  # whether to use syncbn
            kwargs: {}          # kwargs of bn
#eval_list: ["regnetx_3200m", "regnetx_4000m", "regnetx_6400m", "regnety_200m", "regnety_400m", "regnety_600m", "regnety_800m", "regnety_1600m", "regnety_3200m", "regnety_4000m", "regnety_6400m", "bignas_resnet18_9M", "bignas_resnet18_37M", "bignas_resnet18_50M", "bignas_resnet18_49M", "bignas_resnet18_65M", "bignas_resnet18_107M", "bignas_resnet18_125M", "bignas_resnet18_150M", "bignas_resnet18_312M", "bignas_resnet18_403M", "bignas_resnet18_492M", "bignas_resnet18_1555M", "bignas_det_resnet18_1930M", "bignas_resnet50_2954M", "bignas_resnet50_3145M", "bignas_resnet50_3811M", "dmcp_resnet18_47M", "dmna_resnet18_1800M", "shufflenet_v2_x0_5", "shufflenet_v2_x1_0", "shufflenet_v2_x1_5", "shufflenet_v2_x2_0", "oneshot_supcell_9M", "oneshot_supcell_27M", "oneshot_supcell_37M", "oneshot_supcell_55M", "oneshot_supcell_70M", "oneshot_supcell_91M", "oneshot_supcell_96M", "oneshot_supcell_113M", "oneshot_supcell_168M", "oneshot_supcell_304M", "oneshot_supcell_1710M", "oneshot_supcell_3072M", "crnas_resnet18c", "crnas_resnet50c", "crnas_resnet101c", "efficientnet_b0", "efficientnet_b1", "efficientnet_b2", "efficientnet_b3", "efficientnet_b4", "efficientnet_b5", "efficientnet_b6", "efficientnet_b7", "mobilenet_v3_small_x0_35", "mobilenet_v3_small_x0_5", "mobilenet_v3_small_x0_75", "mobilenet_v3_small_x1_0", "mobilenet_v3_small_x1_4", "mobilenet_v3_large_x0_35", "mobilenet_v3_large_x0_5", "mobilenet_v3_large_x0_75", "mobilenet_v3_large_x1_0", "mobilenet_v3_large_x1_4", "googlenet"] #"resnet18c_x0_125", "resnet18c_x0_25", "resnet18c_x0_5", "resnet152", "resnext50_32x4d", "resnext101_32x8d", "wide_resnet50_2", "wide_resnet101_2", "resnet5400"
#eval_list: ["mixer_b16_224", "mixer_L16_224"]
eval_list: ['swin_base_224', 'swin_base_384', 'swin_small', 'swin_tiny']
dist:                     # distributed communication
    sync: False           # if 'True', synchronize gradients after forward 
                          # if 'False', synchronize gradient during forward

optimizer:                # optimizer details
    type: SGD
    kwargs:
        nesterov: True
        momentum: 0.9
        weight_decay: 0.0001

lr_scheduler:             # learning rate scheduler details
    type: StepEpoch
    kwargs:
        lr_epochs: [30, 60, 90]
        lr_mults: [0.1, 0.1, 0.1]

        base_lr: 0.1        # initial leaning rate
        warmup_lr: 0.4      # learning rate after warming up
        warmup_epoch: 2  # epochs of warmup
        max_epoch: 100    # total epochs of training

label_smooth: 0.1         # label smooth ratio
# mixup: 0.2              # mixup ratio
# cutmix: 1.0             # cutmix ratio
ema:                      # exponential moving average details
    enable: False
    kwargs:
        decay: 0.999

lms:                      # large model support: utilize cpu to save gpu memory
    enable: False         # whether to use lms
    kwargs:
        limit: 12         # the soft limit in G-bytes on GPU memory allocated for tensors

data:                     # data details
    type: imagenet        # choices = {'imagenet', 'custom'}
    read_from: fake         # choices = {'mc', 'fs', 'fake', 'osg'}
    use_dali: False       # whether to use NVIDIA dali dataloader
    batch_size: 64        # batch size in one GPU
    num_workers: 4        # number of subprocesses for data loading
    pin_memory: True      # whether to copy Tensors into CUDA pinned memory
    input_size: 224       # training image size
    test_resize: 256      # testing resize image size

    train:                            # training data details
        root_dir: /mnt/lustre/share/images/train/
        meta_file: /mnt/lustre/share/images/meta/train.txt
        image_reader:                 # image decoding type
            type: pil
        sampler:                      # sampler details
            type: distributed_iteration  # distributed iteration-based sampler
        transforms:                   # torchvision transforms, flexible
            # type: STANDARD
            - type: RandomResizedCrop
              kwargs:
                  size: 224
            - type: RandomHorizontalFlip
            - type: ColorJitter
              kwargs:
                  brightness: 0.2
                  contrast: 0.2
                  saturation: 0.2
                  hue: 0.1
            - type: ToTensor
            - type: Normalize
              kwargs:
                  mean: [0.485, 0.456, 0.406]
                  std: [0.229, 0.224, 0.225]

    test:                             # testing data details
        imagenet_c: True
        root_dir: "/mnt/lustrenew/share/xiaotianzi/imagenet-c/imagenet-c-15"
        meta_file: "/mnt/lustrenew/share/xiaotianzi/imagenet-c/label/all.json"
        image_reader:
            type: pil
        sampler:                      # sampler details
            type: distributed         # non-repeated sampling
        transforms:                   # torchvision transforms, flexible
            # type: ONECROP
            - type: Resize
              kwargs:
                  size: [256, 256]
            - type: CenterCrop
              kwargs:
                  size: [224, 224]
            - type: ToTensor
            - type: Normalize
              kwargs:
                  mean: [0.485, 0.456, 0.406]
                  std: [0.229, 0.224, 0.225]

        evaluator:                    # evaluation metric
            type: imagenetc            # choices = {'imagenet', 'custom'}
            kwargs:
                topk: [1, 5]          # compute topk accuracies

saver:                                # saving or loading details
    print_freq: 10                    # frequence of printing logger
    val_freq: 5000                    # frequence of evaluating during training
    save_many: False                  # whether to save checkpoints after every evaluation
    pretrain:                       # pretrain model details
        path: /mnt/lustrenew/xiaotianzi/Spring/prototype-server/exp/baseline-r18/checkpoints/ckpt.pth.tar
    #     ignore:                     # ignore keys in checkpoints
    #         key:                    # if training from scratch, pop 'optimzier' and 'last_iter'
    #             - optimizer         # if resuming from ckpt, DO NOT pop them
    #             - last_iter
    #         model:                  # ignore modules in model
    #             - module.fc.weight  # if training with different number of classes, pop the keys 
    #             - module.fc.bias    # of last fully-connected layers
